source:
  - name: HumanEval
    path: openai/openai_humaneval
    type: huggingface
    sort_key: task_id
    kwargs:
      split: test
  - name: HumanEval-like
    path: data/humaneval_like.json
    type: json
    sort_key: id
  - name: HumanEval-NF
    path: data/humaneval_nf.json
    type: json
    sort_key: id
  - name: cache
    path: results/llama3_8b-codet-nfr/results_merged_1.json
    type: json
    sort_key: id

dataset:
  - name: target
    primary_key: id
    fields:
      - name: id
        source: HumanEval
        key: task_id
      - name: prompt
        source: HumanEval
        key: prompt
      - name: gold_tc
        source: HumanEval-NF
        key: test
        
      - name: plan
        source: cache
        key: plan
      - name: code
        source: cache
        key: plan
      - name: requirements
        source: cache
        key: requirements
      - name: gen_tc
        source: cache
        key: gen_tc

  - name: example
    primary_key: id
    fields:
      - name: id
        source: HumanEval-like
        key: id
      - name: prompt
        source: HumanEval-like
        key: prompt
      - name: requirements
        source: HumanEval-like
        key: requirements
      - name: plan
        source: HumanEval-like
        key: final_plan
      - name: code
        source: HumanEval-like
        key: code
      - name: gen_tc
        source: HumanEval-like
        key: gen_tc

graph:
  entry_point: initialize

  edges:
    - pair: [initialize, __end__]
      type: always

  nodes:
    - name: initialize
      chains:
        # - name: plan
        #   dependencies: []
        #   input_keys: [prompt]
        #   type: cot
        #   kwargs:
        #     n: 10
        #     llm:
        #       max_retries: 1000000
        #       max_tokens: 2048
        #       model: llama3:8b-instruct-fp16
        #       platform: open_webui
        #       temperature: 0.8
        #       top_p: 0.95
        #     parsers:
        #       - type: code_block
        #     prompt:
        #       type: chat
        #       kwargs:
        #         body_template_paths: ["templates/cot/plan"]
        # - name: code
        #   dependencies: [plan]
        #   input_keys: [prompt, plan]
        #   type: cot
        #   kwargs:
        #     n: 1
        #     llm:
        #       max_retries: 1000000
        #       max_tokens: 2048
        #       model: llama3:8b-instruct-fp16
        #       platform: open_webui
        #       temperature: 0
        #       top_p: 1
        #     parsers:
        #       - type: code_block
        #     prompt:
        #       type: chat
        #       kwargs:
        #         body_template_paths: ["templates/cot/plan", "templates/cot/code"]
        - name: gen_tc
          dependencies: []
          input_keys: [prompt]
          type: cot
          kwargs:
            n: 1
            llm:
              max_retries: 1000000
              max_tokens: 2048
              model: llama3:8b-instruct-fp16
              platform: open_webui
              temperature: 0
              top_p: 1
            parsers:
              - type: code_block
              - type: distribute
                kwargs:
                  landmarks:
                    - ["fr", "# Test Cases Regarding Functional Requirements"]
                    - ["general", "## General Cases"]
                    - ["edge", "## Edge Cases"]
                    - ["nfr", "# Test Cases Regarding Non-functional Requirements"]
                    - ["performance", "## Performance Requirements"]
                    - ["sqr", "## Specific Quality Requirements"]
                    - ["robustness", "### Robustness"]
                    - ["maintainability", "### Maintainability"]
            prompt:
              type: chat
              kwargs:
                body_template_paths: ["templates/codet/gen_tc"]

        - name: gen_tc_exec_code
          dependencies: [code, gen_tc]
          input_keys: [code, gen_tc]
          type: custom_lambda
          key_map: { code: code, gen_tc: testcase }
          kwargs:
            src: [code, testcase]
            func: "lambda code, testcase: [code + '\\n\\n' + t.format(prediction=code) for t in testcase]"
        - name: gen_tc_exec_result
          dependencies: [gen_tc_exec_code]
          input_keys: [gen_tc_exec_code]
          type: execute
          kwargs:
            target: gen_tc_exec_code
            timeout: 3
        - name: gen_tc_passed
          dependencies: [gen_tc_exec_result]
          input_keys: [gen_tc_exec_result]
          type: custom_lambda
          kwargs:
            src: [gen_tc_exec_result]
            func: "lambda x: ['Exit Code: 0' in _x for _x in x]"

        - name: gold_tc_exec_code
          dependencies: [code, gold_tc]
          input_keys: [code, gold_tc]
          type: custom_lambda
          key_map: { code: code, gold_tc: testcase }
          kwargs:
            src: [code, testcase]
            func: "lambda code, testcase: code + '\\n\\n' + testcase.format(prediction=code)"
        - name: gold_tc_exec_result
          dependencies: [gold_tc_exec_code]
          input_keys: [gold_tc_exec_code]
          type: execute
          kwargs:
            target: gold_tc_exec_code
            timeout: 3
        - name: passed
          dependencies: [gold_tc_exec_result]
          input_keys: [gold_tc_exec_result]
          type: custom_lambda
          kwargs:
            src: [gold_tc_exec_result]
            func: "lambda x: 'Exit Code: 0' in x"
