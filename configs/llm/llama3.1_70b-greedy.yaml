max_tokens: 2048
model: llama3.1:70b-instruct-fp16
platform: ollama
temperature: 0
top_p: 1
